{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weekly-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "\n",
    "def process_frame(frame, face_detector, facial_landmark_predictor):\n",
    "    framewidth = 600\n",
    "\n",
    "    frame = imutils.resize(frame, width=framewidth)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    face_rectangles = face_detector(gray_frame)  # it is easier to get face rectangle from greyscale image\n",
    "\n",
    "    ear = -1.0\n",
    "\n",
    "    for rect in face_rectangles:\n",
    "        face_shape = facial_landmark_predictor(image=gray_frame, box=rect)\n",
    "        left_eye, right_eye = eye_predictor(face_shape)\n",
    "        draw_eyes(frame, left_eye, right_eye)\n",
    "        ear = (eye_aspect_ratio(left_eye) + eye_aspect_ratio(right_eye)) / 2.0\n",
    "        break  # assuming only one face needs detection as only one driver\n",
    "\n",
    "    return frame, ear\n",
    "\n",
    "\n",
    "def draw_eyes(frame, left_eye, right_eye):\n",
    "    lefteye_hull = cv2.convexHull(left_eye)\n",
    "    righteye_hull = cv2.convexHull(right_eye)\n",
    "    cv2.drawContours(frame, [lefteye_hull], -1, (255, 0, 0), 1)\n",
    "    cv2.drawContours(frame, [righteye_hull], -1, (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "def eye_predictor(face_shape):\n",
    "    # predicting eye using face coordinates\n",
    "    # making it into usable format to calculate EAR\n",
    "    # left eye coordinates from 36 to 41\n",
    "\n",
    "    left = str([face_shape.part(i) for i in get_point_numbers_of_feature('left_eye')])\n",
    "\n",
    "    # right eye coordinates from 42 to 47\n",
    "    right = str([face_shape.part(i) for i in get_point_numbers_of_feature('right_eye')])\n",
    "\n",
    "    left = np.array(\n",
    "        left.replace('[', '').replace(']', '').replace('(', '').replace(')', '').replace('point', '').split(\",\"),\n",
    "        dtype=int).reshape(-1, 2)\n",
    "    right = np.array(\n",
    "        right.replace('[', '').replace(']', '').replace('(', '').replace(')', '').replace('point', '').split(\",\"),\n",
    "        dtype=int).reshape(-1, 2)\n",
    "\n",
    "    return left, right\n",
    "\n",
    "\n",
    "def get_point_numbers_of_feature(feature: str) -> [int]:  # returns point numbers corresponding to a feature\n",
    "    l, h = face_utils.FACIAL_LANDMARKS_IDXS[feature]\n",
    "    return range(l, h)\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # vertical and horzontal distance within the eye\n",
    "\n",
    "    vertical1 = dist.euclidean(eye[1], eye[5])\n",
    "    vertical2 = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "    horizontal = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "    ear_value = (vertical1 + vertical2) / (2.0 * horizontal)\n",
    "\n",
    "    return ear_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-judge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-retreat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
